{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1sKq0oaCQmjBm9ywhsRNR-1W5C33nM3TK",
      "authorship_tag": "ABX9TyOK9EGM6H7Cd80U32gd7DoG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmilijaSvirsk/DeepLearning-CustomModel/blob/main/2lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 lab ;\n",
        "Emilija Svirskytė 2gr ;\n",
        "klasės - bee, ice cream, mushroom"
      ],
      "metadata": {
        "id": "jAmHTKS4yQZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Antras laboratorinis\n",
        "Antroje užduotyje reikia realizuoti vaizdų klasifikavimo modelį. Atsiskaitinėjant pratybų dėstytojas atsiųs testinių vaizdų, su kuriais turėsite pademonstruoti, kaip jūsų realizuotas modelis veikia. Atsiskaitymo metu, turėsite gebėti papasakoti, kaip realizuotas, jūsų modelis. Programinės įrangos sprendimą galite naudoti savo nuožiūra.\n",
        "\n",
        "*   Klasės pasirenkamos savo nuožiūra, tačiau jų turi būti bent 3.\n",
        "*   Duomenų rinkinys turi būti padalintas į mokymo ir testavimo aibes.\n",
        "*   Su testavimo duomenų aibe reikia paskaičiuoti šias metrikas: klasifikavimo matrica (angl. confusion matrix), tikslumas, precizija, atkūrimas ir F1.\n",
        "\n",
        "Duomenų klasėms parinktos iš OpenImages V6 objektų aptikimo uždavinio duomenų rinkinio."
      ],
      "metadata": {
        "id": "9AVN8shiPkiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElMngzNVZO_v",
        "outputId": "c1592b50-f83d-49eb-c90b-4de3d0be3f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transformacijos"
      ],
      "metadata": {
        "id": "6UtK62KUVM5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#validavimo transformacijos\n",
        "transforms_valid = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "thTOw45BVZ8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#treneravimo transformacijos\n",
        "transforms_train = transforms.Compose([\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ColorJitter(brightness = 0.4, saturation = 0.1, hue = 0.1),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "18pVKzN_VR_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Datasets"
      ],
      "metadata": {
        "id": "9CEYXWg6VvE-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9IDWq61Pctw",
        "outputId": "b81f090b-5fd5-4e4b-9ada-2cdca70e652c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 150, Test: 150\n"
          ]
        }
      ],
      "source": [
        "#sukuriam databases\n",
        "data_dir_train = \"drive/MyDrive/GMM_images/train/data\"\n",
        "data_dir_valid = \"drive/MyDrive/GMM_images/valid/data\"\n",
        "\n",
        "train_dataset = torchvision.datasets.ImageFolder(data_dir_train, transform = transforms_train)\n",
        "valid_dataset = torchvision.datasets.ImageFolder(data_dir_valid, transform = transforms_valid)\n",
        "\n",
        "num_workers = 2\n",
        "batch_size = 25\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, num_workers = num_workers, shuffle = True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = batch_size, num_workers = num_workers, shuffle = False)\n",
        "\n",
        "print(f'Train: {len(train_dataset)}, Test: {len(valid_dataset)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelis"
      ],
      "metadata": {
        "id": "5tRPNomYVyE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(torch.nn.Module):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # 3 input image channels, 6 output channels, 3x3 square convolution\n",
        "        self.conv1 = torch.nn.Conv2d(input_shape[0], 6, 3,padding = 'same')\n",
        "        self.conv2 = torch.nn.Conv2d(6, 16, 3,padding = 'same')\n",
        "\n",
        "        self.dropout1 = torch.nn.Dropout(0.25)\n",
        "        self.dropout2 = torch.nn.Dropout(0.5)\n",
        "\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = torch.nn.Linear(16*(input_shape[1] // 4) * (input_shape[2] // 4), 120)\n",
        "        self.fc2 = torch.nn.Linear(120, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        #conv + pool\n",
        "        x = torch.nn.functional.max_pool2d(torch.nn.functional.relu(self.conv1(x)), 2)\n",
        "        x = torch.nn.functional.max_pool2d(torch.nn.functional.relu(self.conv2(x)), 2)\n",
        "\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
        "\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "g3dHVl61QUy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet(train_dataset[0][0].shape, 3).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SV5_yEGq5Zo",
        "outputId": "d73ca7a5-8fee-4141-f80d-f9b9b537a5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvNet(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
            "  (dropout1): Dropout(p=0.25, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=50176, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mokymo ir testavimo funkcijos"
      ],
      "metadata": {
        "id": "ThNLA-kmWFui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Su testavimo duomenų aibe reikia paskaičiuoti šias metrikas: klasifikavimo matrica (angl. confusion matrix), tikslumas, precizija, atkūrimas ir F1."
      ],
      "metadata": {
        "id": "MgJIMGg04L2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Statistics():\n",
        "  def __init__(self):\n",
        "    self.classes = ['bee','ice cream','mushroom']\n",
        "    self.pred_arr = []\n",
        "    self.label_arr = []\n",
        "\n",
        "  def addResultsArray(self, label_arr, pred_arr):\n",
        "    self.pred_arr = np.concatenate((self.pred_arr,pred_arr), axis=None)\n",
        "    self.label_arr = np.concatenate((self.label_arr,label_arr), axis=None)\n",
        "\n",
        "  def getConfusionMatrixDataFrame(self):\n",
        "    return pd.DataFrame(confusion_matrix(self.label_arr,self.pred_arr),\n",
        "                     self.classes,\n",
        "                     self.classes)\n",
        "\n",
        "  def getClassConfusionMatrix(self, label):\n",
        "    TP = 0\n",
        "    TN = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    for i in range(len(self.pred_arr)):\n",
        "      true_result = self.label_arr[i]\n",
        "      prob_result = self.pred_arr[i]\n",
        "      #TP obj exists and model found it\n",
        "      if((true_result==prob_result) and (prob_result==label)):\n",
        "        TP+=1\n",
        "      #TN obj doesnt exist and model didnt find it\n",
        "      elif((true_result!=prob_result) and (true_result!=label) and (prob_result!=label)):\n",
        "        TN+=1\n",
        "      #FP obj exists but model didnt find it\n",
        "      elif((true_result!=prob_result) and (true_result==label)):\n",
        "        FP+=1\n",
        "      #FN obj doesnt exist but model found it\n",
        "      elif((true_result!=prob_result) and (prob_result==label)):\n",
        "        FN+=1\n",
        "    return {\"TP\":TP,\"TN\":TN,\"FP\":FP,\"FN\":FN}\n",
        "\n",
        "  def getStatistics(self, matrix):\n",
        "    TP = matrix['TP']\n",
        "    TN = matrix['TN']\n",
        "    FP = matrix['FP']\n",
        "    FN = matrix['FN']\n",
        "    stats = {}\n",
        "\n",
        "    if((TP + FP + TN + FN)==0):\n",
        "      stats['accuracy'] = 0\n",
        "    else:\n",
        "      stats['accuracy'] = (TP + TN) / (TP + FP + TN + FN)\n",
        "    if((TP + FN)==0):\n",
        "      stats['recall'] = 0\n",
        "    else:\n",
        "      stats['recall'] = TP / (TP + FN)\n",
        "    if((TP + FP)==0):\n",
        "      stats['precision'] = 0\n",
        "    else:\n",
        "      stats['precision'] = TP / (TP + FP)\n",
        "    if((stats['precision'] + stats['recall'])==0):\n",
        "      stats['f1'] = 0\n",
        "    else:\n",
        "      stats['f1'] = 2 * (stats['precision'] * stats['recall']) / (stats['precision'] + stats['recall'])\n",
        "\n",
        "    return stats\n"
      ],
      "metadata": {
        "id": "DQaCdLcK3826"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seconds_to_time(seconds):\n",
        "    s = int(seconds) % 60\n",
        "    m = int(seconds) // 60\n",
        "    if m < 1:\n",
        "        return f'{s}s'\n",
        "    h = m // 60\n",
        "    m = m % 60\n",
        "    if h < 1:\n",
        "        return f'{m}m{s}s'\n",
        "    return f'{h}h{m}m{s}s'"
      ],
      "metadata": {
        "id": "cXv0vml2ZtOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(optimizer, loss_func, model, loader):\n",
        "  num_classes = model.num_classes\n",
        "  #pakeiciam moda\n",
        "  model.train()\n",
        "  loss_acum = np.array([], dtype = np.float32)\n",
        "\n",
        "  for data in loader:\n",
        "    #duomenys\n",
        "    images = data[0].to(device)\n",
        "    #create label array\n",
        "    labels = torch.nn.functional.one_hot(data[1], num_classes).float().to(device)\n",
        "\n",
        "    pred = model(images)\n",
        "    loss = loss_func(pred, labels)\n",
        "    loss_acum = np.append(loss_acum, loss.cpu().detach().numpy())\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return np.mean(loss_acum)"
      ],
      "metadata": {
        "id": "K9CEgf2KRCFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader):\n",
        "  #pakeiciam moda\n",
        "  model.eval()\n",
        "\n",
        "  correct_predictions = 0\n",
        "  total_predictions = 0\n",
        "\n",
        "  label_arr = []\n",
        "  pred_arr = []\n",
        "\n",
        "  for data in loader:\n",
        "    images = data[0].to(device)\n",
        "    labels = data[1].to(device)\n",
        "    #print(labels)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      pred = model(images)\n",
        "\n",
        "    label_pred = torch.argmax(pred, axis = 1)\n",
        "\n",
        "    correct_predictions += torch.sum(labels == label_pred)\n",
        "    total_predictions += images.shape[0]\n",
        "\n",
        "    #statistics\n",
        "    label_arr.append(labels.cpu().numpy())\n",
        "    pred_arr.append(label_pred.cpu().numpy())\n",
        "\n",
        "  accuracy = correct_predictions / total_predictions\n",
        "  return accuracy, label_arr, pred_arr"
      ],
      "metadata": {
        "id": "YwvM_y1JUhfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_eval(model, loader_train, loader_valid, epoch_count = 21, lr = 1e-3):\n",
        "  #entropy and adam\n",
        "  loss_func = torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "  start_time = datetime.now()\n",
        "\n",
        "  train_accuracy_acum = []\n",
        "  valid_accuracy_acum = []\n",
        "\n",
        "  for epoch in range(epoch_count):\n",
        "    loss = train_epoch(optimizer, loss_func, model, loader_train)\n",
        "\n",
        "    train_accuracy, label_arr_train, pred_arr_train  = evaluate(model, loader_train)\n",
        "    train_accuracy_acum.append(train_accuracy.cpu().numpy())\n",
        "    valid_accuracy, label_arr_valid, pred_arr_valid  = evaluate(model, loader_valid)\n",
        "    valid_accuracy_acum.append(valid_accuracy.cpu().numpy())\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "      current_time = datetime.now()\n",
        "      elapsed = seconds_to_time((current_time - start_time).total_seconds())\n",
        "      print(f'Epoch: {epoch}, Time: {elapsed}, Training loss: {loss}')\n",
        "      print(f'  Training accuracy: {torch.round(train_accuracy * 100)}, Validation accuracy: {torch.round(valid_accuracy * 100)}')\n",
        "\n",
        "  return train_accuracy_acum, valid_accuracy_acum"
      ],
      "metadata": {
        "id": "6wfgaEmfU9Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testing(model, loader, stats):\n",
        "  valid_accuracy, label_arr_valid, pred_arr_valid  = evaluate(model, loader)\n",
        "  stats.addResultsArray(label_arr_valid, pred_arr_valid)\n"
      ],
      "metadata": {
        "id": "W_3o4avmiYdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelio treneravimas ir ivertinimas"
      ],
      "metadata": {
        "id": "xWI4q4QEZAY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracy(train_accuracy, valid_accuracy):\n",
        "  plt.clf()\n",
        "  plt.plot(train_accuracy, 'b', label = 'Training accuracy')\n",
        "  plt.plot(valid_accuracy, 'r', label = 'Validation accuracy')\n",
        "  plt.ylim(0.0, 1.0)\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "gaPIQPNeVCMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet(train_dataset[0][0].shape, 3).to(device)\n",
        "print(f'Parameter count: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
        "\n",
        "train_acc, valid_acc = train_and_eval(model, train_loader, valid_loader)\n",
        "plot_accuracy(train_acc, valid_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "INZB274qY-8-",
        "outputId": "3e59ae14-f9b0-4bdc-9062-133792c67fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter count: 6,022,651\n",
            "Epoch: 0, Time: 11s, Training loss: 2.029587507247925\n",
            "  Training accuracy: 40.0, Validation accuracy: 32.0\n",
            "Epoch: 5, Time: 1m6s, Training loss: 1.0298324823379517\n",
            "  Training accuracy: 54.0, Validation accuracy: 59.0\n",
            "Epoch: 10, Time: 2m2s, Training loss: 0.9322444796562195\n",
            "  Training accuracy: 65.0, Validation accuracy: 59.0\n",
            "Epoch: 15, Time: 2m57s, Training loss: 0.7694645524024963\n",
            "  Training accuracy: 72.0, Validation accuracy: 63.0\n",
            "Epoch: 20, Time: 3m53s, Training loss: 0.7089090347290039\n",
            "  Training accuracy: 73.0, Validation accuracy: 55.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats = Statistics()\n",
        "testing(model, valid_loader, stats)\n",
        "\n",
        "print(stats.getConfusionMatrixDataFrame())\n",
        "\n",
        "#bee category\n",
        "print(\"\\nbee category:\")\n",
        "matrix = stats.getClassConfusionMatrix(0)\n",
        "print(matrix)\n",
        "statistics = stats.getStatistics(matrix)\n",
        "print(statistics)\n",
        "\n",
        "#ice cream category\n",
        "print(\"\\nice cream category:\")\n",
        "matrix = stats.getClassConfusionMatrix(1)\n",
        "print(matrix)\n",
        "statistics = stats.getStatistics(matrix)\n",
        "print(statistics)\n",
        "\n",
        "#mushroom category\n",
        "print(\"\\nmushroom category:\")\n",
        "matrix = stats.getClassConfusionMatrix(2)\n",
        "print(matrix)\n",
        "statistics = stats.getStatistics(matrix)\n",
        "print(statistics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_V3KljhjKVl",
        "outputId": "9f5a9958-6f04-4596-976e-9af740561484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           bee  ice cream  mushroom\n",
            "bee         36          6         8\n",
            "ice cream   26         12        12\n",
            "mushroom    15          0        35\n",
            "\n",
            "bee category:\n",
            "{'TP': 36, 'TN': 12, 'FP': 14, 'FN': 41}\n",
            "{'accuracy': 0.46601941747572817, 'recall': 0.4675324675324675, 'precision': 0.72, 'f1': 0.5669291338582677}\n",
            "\n",
            "ice cream category:\n",
            "{'TP': 12, 'TN': 23, 'FP': 38, 'FN': 6}\n",
            "{'accuracy': 0.4430379746835443, 'recall': 0.6666666666666666, 'precision': 0.24, 'f1': 0.3529411764705882}\n",
            "\n",
            "mushroom category:\n",
            "{'TP': 35, 'TN': 32, 'FP': 15, 'FN': 20}\n",
            "{'accuracy': 0.6568627450980392, 'recall': 0.6363636363636364, 'precision': 0.7, 'f1': 0.6666666666666666}\n"
          ]
        }
      ]
    }
  ]
}